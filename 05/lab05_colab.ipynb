{"cells":[{"cell_type":"markdown","metadata":{"id":"oXOIOHacny_P"},"source":["# Lab05 - Color\n","### TDS3651 Visual Information Processing\n"]},{"cell_type":"code","source":["#install ipympl for interactive figure in Google Colab\n","!pip install ipympl"],"metadata":{"id":"HRB9p4kvpwUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"m-QE_ITtoC_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Subjects/TDS3651/2210/Labs/Lab05/'"],"metadata":{"id":"GTJgs30goBtG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ww2FThl1ny_U"},"source":["This lab will guide you how color images can be handled, processed and converted between various colorspaces."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14IuK5Y6ny_U"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"zjdsYzKkny_W"},"source":["## Processing Color Images"]},{"cell_type":"markdown","metadata":{"id":"GSx3uhHBny_W"},"source":["Let's read our favourite flower picture: `redflower.jpg`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cdz3dxyony_X"},"outputs":[],"source":["img = cv2.imread(path+'redflower.jpg')\n","img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(img)\n","plt.title('Red flower')\n","plt.xticks([]), plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","source":["Let's attempt to show the 3 channel slices (Red, Green, Blue) separately."],"metadata":{"id":"YlKFxnIxpID-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qqo3_ZVnny_Z"},"outputs":[],"source":["# accessing each slice (in the 3rd dimension) of the color image array\n","R = img[:,:,0]\n","G = img[:,:,1]\n","B = img[:,:,2]\n","\n","# horizontal stacking of the 3 images\n","allthree = np.hstack((R,G,B))\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(allthree,cmap='gray', vmin=0,vmax=255)\n","plt.xticks([]), plt.yticks([])\n","plt.title('R - G - B channels')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"F-2A4slcny_a"},"source":["Observe how the red channel slice has a high intensity value (whitish) at the flower areas.\n"]},{"cell_type":"markdown","metadata":{"id":"iwaDqCCnny_a"},"source":["### Converting to other colorspaces"]},{"cell_type":"markdown","metadata":{"id":"Z-SicOkgny_b"},"source":["Let's convert to the HSV colorspace."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q00ZTZ3eny_b"},"outputs":[],"source":["# Convert BGR to HSV (no need go to RGB first)\n","hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(hsv)\n","plt.xticks([]), plt.yticks([])\n","plt.title('HSV image')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2mHlnCKuny_b"},"source":["The \"HSV\" image does not really show anything meaningful enough for us to understand more..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pv9olhiKny_c"},"outputs":[],"source":["H = hsv[:,:,0]\n","S = hsv[:,:,1]\n","V = hsv[:,:,2]\n","HSVallthree = np.hstack((hsv[:,:,0],hsv[:,:,1],hsv[:,:,2]))\n","\n","# interestingly, the range of values for H is [0, 179] for 8-bit images. This is fixed by OpenCV for HSV\n","print(np.max(H), np.min(H))\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(HSVallthree,cmap='gray')\n","plt.xticks([]), plt.yticks([])\n","plt.title('H - S - V channels')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EzK-25Zlny_c"},"source":["Matplotlib's `imshow` function, allows us to colour the values according to a certain colormap. A `hsv` colormap is available, which is based on a cyclic red-yellow-green-cyan-blue-magenta-red. This should show us where the hues are in the picture.\n","\n","**Note**: The Saturation (S) at the flower petal region is quite high, indicating that the red colours there are very pure and close to a full red. The Value (V) channel is very close to a grayscale version of the original color image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tg_reIs9ny_c"},"outputs":[],"source":["ax = plt.imshow(H, cmap='hsv')\n","cax = plt.colorbar(ax, ticks=[0,179])\n","plt.show();"]},{"cell_type":"markdown","metadata":{"id":"HsH_iVfCny_c"},"source":["**Note**: The coloring here shows all hues at the highest saturation level (hence, the colours are very vibrant and pure). Only by including the Saturation channel together, we will get closer to the original colours of the image."]},{"cell_type":"markdown","metadata":{"id":"J0lYsEj-ny_d"},"source":["**Q1**: Experiment with other colorspaces like **YCbCr** (attach the conversion flag `CV_RGBYCrCb`), **CIE XYZ** (attach the conversion flag `CV_RGB2XYZ`) and **CIE LAB** (attach the conversion flag `CV_RGB2Lab`). Note down your observations.\n","\n","For more information, check out the documentation for [`cv2.cvtColor()`](http://docs.opencv.org/3.0-beta/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1pySep-ny_d"},"outputs":[],"source":["#convert image to the different color spaces\n","#show the image in color and also the individual channels (in gray cmap) side-by-side\n","#inspect the minimum and maximum values of each channel\n","#(print as title when showing image)\n"]},{"cell_type":"markdown","metadata":{"id":"BvlPZZbcny_d"},"source":["### Detecting Color Objects\n","\n","Now that we know how to get the hues from HSV, we can use this to extract colored objects from an image. In the following steps, we will try to extract the oranges from the apples.\n","\n","First, we need to define a range for the colour that we intend to detect in HSV.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ei2QE5Muny_e"},"outputs":[],"source":["aao = cv2.imread(path+'apples_oranges.jpg')\n","aao = cv2.cvtColor(aao,cv2.COLOR_BGR2RGB)\n","aao_hsv = cv2.cvtColor(aao, cv2.COLOR_RGB2HSV)\n","\n","#turn interactive plot on\n","%matplotlib ipympl\n","from google.colab import output\n","output.enable_custom_widget_manager()\n","\n","plt.figure(figsize=(10,10))\n","plt.imshow(aao_hsv, cmap='hsv')\n","plt.show();"]},{"cell_type":"markdown","metadata":{"id":"paLxHwTCny_e"},"source":["With the interative plot enabled, use it to discover a suitable range for the orange colour in HSV coordinate. Note that the Hue value must be scaled to a value between 0 and 179."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABF15NqLny_e"},"outputs":[],"source":["# turn interactive plot off\n","output.disable_custom_widget_manager()\n","%matplotlib inline\n","\n","# define range of orange color in HSV\n","lower_orange = np.array([5,225,175])\n","upper_orange = np.array([15,255,255])"]},{"cell_type":"markdown","metadata":{"id":"YMAwrv3iny_e"},"source":["Next, threshold the HSV image using the orange color range specified earlier. <br>\n","We will be using the [`cv2.inRange`](https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981) function that can defined a lower and upper threshold."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2RX7gI1ny_f"},"outputs":[],"source":["# Threshold the HSV image to get only orange colors\n","mask = cv2.inRange(aao_hsv, lower_orange, upper_orange)\n","plt.imshow(mask,cmap='gray')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kgrtonfLny_f"},"source":["Do a bitwise-AND on the mask and original image. This acts to superimpose the detected colour onto the original image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6z8AUJWwny_f"},"outputs":[],"source":["# Bitwise-AND mask and original image\n","res = cv2.bitwise_and(aao, aao, mask=mask)\n","\n","plt.figure(figsize=(5,5))\n","plt.imshow(res)\n","plt.title('Detected oranges')\n","plt.xticks([]), plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Mz0-QsnQny_f"},"source":["Not satisfied with it? <br>\n","\n","**Hints:**\n","- Try to find appropriate threshold boundaries for each channel (H, S, V).\n","- You may use histograms to analyse manually, or you can also use an *automatic threshold finding method* (both to be covered later)."]},{"cell_type":"markdown","metadata":{"id":"gD9KSmqKny_f"},"source":["## Color Histograms\n","\n","The histograms for each of the color channels is a straightforward way of representing the distribution of color intensity values. Two images that are quite similar in **content** (e.g. two pictures of panda bears) are likely to have the same distribution of colour intensities. This can potentially be useful for performing matching between images, and further to that, for image search/retrieval task.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5PlXG5Nny_g"},"outputs":[],"source":["redflower = cv2.imread(path+'redflower.jpg')\n","rf = cv2.cvtColor(redflower, cv2.COLOR_BGR2RGB)\n","r, g, b = rf[:,:,0], rf[:,:,1], rf[:,:,2]\n","\n","plt.figure(figsize=(7,6))\n","plt.subplot(311)                             #plot in the first cell\n","plt.subplots_adjust(hspace=.5)\n","plt.title(\"Red\")\n","plt.hist(np.ndarray.flatten(r), bins=128)\n","plt.subplot(312)                             #plot in the second cell\n","plt.title(\"Green\")\n","plt.hist(np.ndarray.flatten(g), bins=128)\n","plt.subplot(313)                             #plot in the third cell\n","plt.title(\"Blue\")\n","plt.hist(np.ndarray.flatten(b), bins=128)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"88C3mLi8ny_g"},"source":["Note that we are showing the histogram using only 128 bins (which means, every two values occupy one bin drawn). You can increase this value for finer bins or decrease this value for coarser bins.\n","\n","**Q2**: For ease of future use, write a general function to display the histogram of all three channels, in the similar way to that shown above:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BGsZ0tRTny_g"},"outputs":[],"source":["def allChannelHist(img, bins=128):\n","    # add your code\n","\n","#Test function:\n","redflower = cv2.imread(path+'redflower.jpg')\n","allChannelHist(redflower,16)"]},{"cell_type":"markdown","metadata":{"id":"WkSNQWZkny_g"},"source":["To form a single colour histogram, concatenate all three histograms into a single array. For that, use `numpy.histogram` to get the individual histograms of each channel before concatenation. After concatenating, use the `bar` function to show the histogram as a bar plot."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"MCWOJPALny_h"},"outputs":[],"source":["r_hist, r_bin = np.histogram(r, 128)\n","g_hist, g_bin = np.histogram(g, 128)\n","b_hist, b_bin = np.histogram(b, 128)\n","rgb_hist = np.concatenate((r_hist, g_hist, b_hist))\n","pos = np.arange(384)\n","plt.bar(pos, rgb_hist), plt.title('RGB Color histogram')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ORtijGmJny_h"},"source":["An important step to ensure the histogram is independent from image size/number of pixels, is to normalize each individual channel histogram (so that the values within each histogram sums to 1), before concatenating them together. The histogram will \"look\" the same though."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEqMlOLany_h"},"outputs":[],"source":["r_hist, r_bin = np.histogram(r, 128, density=True)\n","g_hist, g_bin = np.histogram(g, 128, density=True)\n","b_hist, b_bin = np.histogram(b, 128, density=True)\n","rgb_hist = np.concatenate((r_hist, g_hist, b_hist))\n","pos = np.arange(384)\n","plt.bar(pos, rgb_hist), plt.title('RGB Color histogram (normalized)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zC1mbgR2ny_i"},"source":["**Q3**: Transfer the code that is to be used to create the colour histogram into a useful function called `colorHistogram()`, which performs the necessary colorspace conversion, histogramming of channels, and concatenation. The function should take in an image, the colorspace and bin size (3 inputs), and return the colour histogram as output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eqa3RtUfny_i"},"outputs":[],"source":["#assume input originally BGR\n","def colorHistogram(img, cspace='RGB', binsize=128):\n","   # Add you code here\n","\n","\n","\n","rf_hist = colorHistogram(img)"]},{"cell_type":"markdown","metadata":{"id":"M_QfAP9Gny_i"},"source":["With the function done, it's now easy to convert any image to a color histogram (based on the colorspace desired). Let's use it on other images now."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKurMyWEny_j"},"outputs":[],"source":["mg = cv2.imread(path+'morning_glory.jpg')\n","ant = cv2.imread(path+'anthurium.jpg')\n","yf = cv2.imread(path+'yellowflower.jpg')\n","\n","mg_hist = colorHistogram(mg)\n","ant_hist = colorHistogram(ant)\n","yf_hist = colorHistogram(yf)"]},{"cell_type":"markdown","metadata":{"id":"Gn71MFQ4ny_j"},"source":["#### Matching images\n","\n","The concept of \"matching\" images is as simple as finding out how far an image is from another image. However, if we were to use raw pixels to compare, it is unlikely we are able to make any meaningful measurements, especially when they are taken from different angles.\n","<!-- <table >\n","    <tr><td><img src=\"redflower.jpg\" style=\"width:150px\"></td>\n","    <td><img src=\"anthurium.jpg\" style=\"width:150px\"></td></tr>\n","     <tr><td>redflower.jpg</td><td>anthurium.jpg</td><td></tr>\n","     <tr><td><img src=\"morning_glory.jpg\" style=\"width:150px\"></td>\n","    <td><img src=\"yellowflower.jpg\" style=\"width:150px\"></td></tr>\n","    <tr><td>morning_glory.jpg</td><td>yellowflower.jpg</td></tr>\n","</table> -->\n","\n"]},{"cell_type":"code","source":["redflower = cv2.cvtColor(cv2.imread(path+'redflower.jpg'),cv2.COLOR_BGR2RGB)\n","mg = cv2.cvtColor(cv2.imread(path+'morning_glory.jpg'),cv2.COLOR_BGR2RGB)\n","ant = cv2.cvtColor(cv2.imread(path+'anthurium.jpg'),cv2.COLOR_BGR2RGB)\n","yf = cv2.cvtColor(cv2.imread(path+'yellowflower.jpg'),cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(10,10))\n","plt.subplot(221), plt.imshow(redflower), plt.title('redflower'), plt.xticks([]), plt.yticks([])\n","plt.subplot(222), plt.imshow(ant), plt.title('anthurium'), plt.xticks([]), plt.yticks([])\n","plt.subplot(223), plt.imshow(mg), plt.title('morning glory'), plt.xticks([]), plt.yticks([])\n","plt.subplot(224), plt.imshow(yf), plt.title('yellow flower'), plt.xticks([]), plt.yticks([])\n","plt.show()"],"metadata":{"id":"b8sYdo9DsoX9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using their colour histograms is *probably* better, since we can see that their composition of colours involve some red areas, and other areas that are greenish and dark.\n","\n","The simplest way is to use an Euclidean distance (straight line distance between two points of dimension $D$). When $D=2$, this is how it is:\n","<!-- <img src=\"distance.png\" style=\"width:300px\"> -->\n"],"metadata":{"id":"B0s9hem-sk43"}},{"cell_type":"code","source":["d = cv2.imread(path+'distance.png',0)\n","plt.figure(figsize=(5,5))\n","plt.imshow(d,cmap='gray'), plt.xticks([]), plt.yticks([])\n","plt.title('Types of Distance')\n","plt.show()"],"metadata":{"id":"urN3lz71whWt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Likewise, if we are using the colour histograms, think of $D=384$. There are $128$ bins $\\times \\hspace{0.2em} 3$ channels of numbers, representing each image.\n","\n","There's a nice set of distance functions from `scipy.spatial` that we can use straight out of the box (no need for us to implement!). Let's verify if the distance calculated is correct using a simple example of two 1-D arrays."],"metadata":{"id":"YtVjjOVcwcn2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8nBakGuny_j"},"outputs":[],"source":["from scipy.spatial import distance\n","a = [1,2,3]\n","b = [4,5,6]\n","d = distance.euclidean(a,b)\n","print(d)"]},{"cell_type":"markdown","metadata":{"id":"C08_DT5Iny_j"},"source":["Now, let's compare the distance between the `redflower` and the other 3 flower images..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XxO3BbV2ny_k"},"outputs":[],"source":["dist1 = distance.euclidean(rf_hist, ant_hist)\n","dist2 = distance.euclidean(rf_hist, mg_hist)\n","dist3 = distance.euclidean(rf_hist, yf_hist)\n","\n","print((dist1, dist2, dist3))\n"]},{"cell_type":"markdown","metadata":{"id":"_oGIYdK4ny_k"},"source":["The distances show that the `morning_glory` is the nearest to the `redflower` while the `yellowflower` is the furthest. We were expecting the `anthurium` to be the closest to the `redflower` but turns out, that didn't work out.\n","\n","**Q4**: Re-run this experiment using HSV color histogram, just the Hue channel histogram alone. See if the distance measurements make more sense."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"nUbhT_JPny_k"},"outputs":[],"source":["\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k0zBQ5RNny_k"},"source":["### Trying Pillow & scikit-image packages\n","\n","Our practicals will be mostly focused on the OpenCV library. Feel free to try out some hands-on tutorial on the other two libraries: [Pillow](https://pillow.readthedocs.io/en/latest/handbook/tutorial.html) and [`scikit-image`](http://www.scipy-lectures.org/packages/scikit-image/index.html#introduction-and-concepts).\n","\n","Most of these basic operations covered in this module are available on all three libraries. Perhaps the comprehensiveness of the OpenCV library would be most telling in the advanced topics."]},{"cell_type":"markdown","metadata":{"id":"kjIHjkeMny_l"},"source":["## Additional Exercises\n"]},{"cell_type":"markdown","metadata":{"id":"08sYKr5Xny_l"},"source":["**Q1**. **Histogram intersection** is another distance measure which is popularly used to match image features that are in the form of histograms. It is given in formula as:\n","$$\\mathcal D(H(\\mathbf{X}),H(\\mathbf{Y}))=\\sum_j^n \\min(H(\\mathbf{X_j}), H(\\mathbf{Y_j}))\\qquad \\text{with } n \\text{ bins}$$\n","Write a function `histogram_intersection` to implement this. Test it out on the color histograms generated earlier in this lab exercise.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xg5HsYJ8ny_l"},"outputs":[],"source":["\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"h6FQtsoiny_m"},"source":["**Q2**:Perform segmentation on the given image to extract all the cars. Create masks using color information of different groups of cars. If necessary, different color spaces and other techniques from previous classes can be applied as well to improve the segmentation results. <br>\n","<!-- ![Colored Cars](colored_cars.png) -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4G2rUqvny_m"},"outputs":[],"source":["\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZZQRujq5ny_l"},"source":["**Q3**: **Pop-Art** is an art movement that emerged in the mid-1950s in Britain and the late 1950s in the United States. One of the most widely known style of pop art is one created by Andy Warhol, which uses a small palette of distinct hues (they can be often bright and highly saturated, or moody and tinted in certain settings). Here's the original photo of Marilyn Monroe, and the famous pop-art version created by Andy Warhol:\n","<!-- ![Original Marilyn Monroe](marilyn.png)![Pop Art Marilyn Monroe](popart_marilyn.png) -->"]},{"cell_type":"code","source":[],"metadata":{"id":"7yDgFELDuqG1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Give a shot at generating cool pop art images of real-life people and objects!\n","\n","Hint: Here's a typical five-color pop art palette:\n","<!-- ![Pop-art Kiss Palette](popart_palette.png) -->"],"metadata":{"id":"_KceZeBFuogf"}},{"cell_type":"code","source":["palette = cv2.cvtColor(cv2.imread(path+'popart_palette.png'),cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(10,10))\n","plt.imshow(palette), plt.xticks([]), plt.yticks([])\n","plt.title('Pop-art Kiss Palette')\n","plt.show()"],"metadata":{"id":"plduZ4p6uJEu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["These colors are given by these values: (240, 24, 72), (192, 78, 168), (144, 192, 144), (240, 216, 120), (240, 192, 0)\n","Try to assign values from different grayscale ranges to these different colours.<br><br>\n","Try out these tasks:\n","1. Use the artist version to create masks and assign new colors for your own pop-art on the original image.\n","2. Assign values from different grayscale ranges in the original image to the different given colours."],"metadata":{"id":"FXQQU11iuDJf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEoNUUDRny_l"},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}